0. Depends on the AutoEncoder code (repo:https://bitbucket.org/BeulahWorks/autoencoder/src/master/). 

1. There are 2 java classes: 
a. BasicOperationOnMatrix: singleton, includes all basic linear regression operations.
b. Ella: includes all high level operations described in the ELLA paper.

2. Usage:
a. Call Autoencoder.sparkAutoEncoder() to get the model and the autoencoded table.
b. Create an Ella object by calling its constructor. 1st parameter is k (number of latent tasks / model parameters) and 2nd is d (the length of features as the autoencoder output). See the paper for details.
c. Call Ella.startJob(). 
1st param is the spark dataframe's name, which contains both a vector column (aggregation of all features, required by spark's classifiers) and all raw columns/features. 
2nd param is the name of the vector column. It's an output of the autoencoder.

The caller (R code) need to combine any new dataset with old ones and pass it to this function. The dataset name should remain same if it's an older task.
It returns the trained model's theta.

d. Caller (R code) then build a logistic regression model using the new theta and use that model for prediction.

Limitations: 
1. currently it only supports binary classification, because spark's logistic regression model gives 1 theta (model parameter) which matches the ELLA algorithm.
For multiclass classification, spark will output multiple thetas and we still need to figure out how to use that with ELLA. Also it may affects the loss function derivative.

2. Currently the algorithm uses 0.5 as the model threshold. 
Spark's logistic regression allows changing the threshold. This is helpful when working with unbalanced class labels. This feature needs to be implemented in future.

